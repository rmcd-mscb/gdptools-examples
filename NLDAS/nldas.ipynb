{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHGF application demo: Calculating zonal stats for NLDAS zarr data using gdptools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo calculates an area-weighted mean NLDAS Soil Moisture (kg/m^2) for 10-digit Hydrologic Unit (HU10) region polygons covering the Saint Croix River watershed, which includes the HU4 of 0703 in Minnesota and Wisconsin for one time step within the full time series of gridded hourly NLDAS Mosaic model output. The polygon area-weighted mean calculation is carried out using the [gdptools library](https://code.usgs.gov/wma/nhgf/toolsteam/gdptools), and the results are visualized using hvplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements include fsspec, holoviews, numpy, pandas, geopandas, ujson, s3fs, fsspec, and kerchunk. It is recommended to build a conda environment from the environment.yml file in gdptools in order to be able to use the gdptools for calculating and plotting polygon-weighted mean NLDAS soil moisture values: https://code.usgs.gov/wma/nhgf/toolsteam/gdptools.\n",
    "\n",
    "```conda env create -f environment.yml```\n",
    "\n",
    "Once the conda environment is created, activate gdptools, `conda activate gdptools`, and run `poetry install` to build the environment.\n",
    "\n",
    "For those not using the gdptools environment file, it is recommended to use pip to install kerchunk, as the current version on conda-forge is not up-to-date.\n",
    "\n",
    "```pip install git+https://github.com/fsspec/kerchunk.git```\n",
    "\n",
    "Users will also need the [AWS command line interface (CLI) tools](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html), an AWS account, and an [AWS credentials file](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html) with a profile which has the AWS Access Key ID and AWS Secret Access Key for the NHGF S3 bucket. This notebook assumes there is a profile in the AWS credentials file for the NHGF bucket which has the name \"NHGF\". This credentials file should be under ~/.aws/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import os\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import hvplot.xarray\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cartopy\n",
    "import pyproj\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from gdptools.helpers import generate_weights\n",
    "from gdptools.helpers import _get_cells_poly\n",
    "from gdptools.helpers import get_crs\n",
    "from gdptools.helpers import run_weights\n",
    "\n",
    "fs = fsspec.filesystem('file') # Set local file system\n",
    "\n",
    "proj_dir = 's3://nhgf-development/nldas' # NHGF S3 bucket location\n",
    "json_dir = f'{proj_dir}/data/jsons'\n",
    "\n",
    "var = 'SOILM'\n",
    "timedimension = 'time'\n",
    "\n",
    "# Import Saint Croix Watershed HU10 polygons\n",
    "hucpoly = '~/data/Saint_Croix_HU10_5070.geojson'\n",
    "with fs.open(hucpoly, mode='r') as file:\n",
    "    gdf = gpd.read_file(file)\n",
    "# gdf = gpd.read_file('../tests/data/hru_1210.shp')\n",
    "gdf\n",
    "polygon_index = 'huc10'\n",
    "print(gdf.crs)\n",
    "\n",
    "# # Import State Boundary Polygons\n",
    "statespoly = '~/data/tl_2012_us_state.geojson'\n",
    "with fs.open(statespoly, mode='r') as file:\n",
    "    states = gpd.read_file(file)\n",
    "\n",
    "states.to_crs(epsg='5070', inplace=True)\n",
    "print(states.crs)\n",
    "\n",
    "timeidxstart = 1600\n",
    "timeidxend = timeidxstart + 1\n",
    "\n",
    "mosaicmultizarr = f'{json_dir}/mosaic_SOILM.json' # Path to zarr virtual dataset for mosaic model soil moisture data\n",
    "\n",
    "# Storage and read options to access S3 bucket\n",
    "s_opts = {'requester_pays':True, 'skip_instance_cache':True, 'profile':'NHGF'}\n",
    "r_opts = {'anon':False, 'profile':'NHGF'}\n",
    "# Set file system with configuration to access S3 bucket\n",
    "mosaicfs = fsspec.filesystem(\n",
    "    'reference', \n",
    "    fo=mosaicmultizarr, \n",
    "    ref_storage_args=s_opts, \n",
    "    remote_protocol='s3', \n",
    "    remote_options=r_opts, \n",
    "    profile='NHGF')\n",
    "\n",
    "mosaicmapper = mosaicfs.get_mapper(\"\")\n",
    "# Open virtual dataset using xarray. This will only load in metadata\n",
    "mosaic_combo = xr.open_dataset(mosaicmapper, engine=\"zarr\", backend_kwargs={'consolidated':False}, chunks={})\n",
    "# Extract surface (0-10 meters) soil moisture from dataset\n",
    "surface_mosaic = mosaic_combo.SOILM[:,0,:,:]\n",
    "surface_mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "bbox = box(*gdf.to_crs(4326).total_bounds)\n",
    "gdf_bounds = bbox.buffer(2*max(max(np.diff(surface_mosaic.lat.values)), max(np.diff(surface_mosaic.lon.values)))).bounds\n",
    "gdf_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "subset_dict = {'lon': slice(gdf_bounds[0], gdf_bounds[2]),\n",
    "               'lat': slice(gdf_bounds[1], gdf_bounds[3]),\n",
    "               'time': slice(pd.to_datetime('1979-01-02T01:00:00.000000000'),pd.to_datetime('1979-01-02T02:00:00.000000000')),\n",
    "               'depth': 5}\n",
    "print(subset_dict)\n",
    "ds_ss = mosaic_combo.sel(**subset_dict)\n",
    "ds_ss.SOILM.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quickly plot selected time slice\n",
    "# mosaic_combo.SOILM.isel(time=timeidxstart, depth=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dataset and select time slice\n",
    "data = ds_ss\n",
    "# # Extract date for time slice\n",
    "# date = str(pd.to_datetime(data.coords['time'].values[0]).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize grid cells to polygons \n",
    "gridpoly = _get_cells_poly(ds_ss.isel(time=0), x='lon', y='lat', var=var, crs_in=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridpoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geodataframe from vectorized grid cells\n",
    "gdf_grid = gridpoly\n",
    "gdf_grid.to_crs(epsg='5070', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate weights of the proportion of the grid cells covering each HU10 polygon\n",
    "weightspath = f'tmp_stcroix_wgts.csv'\n",
    "\n",
    "wght_n = generate_weights(\n",
    "    poly=gdf,\n",
    "    poly_idx=polygon_index,\n",
    "    grid_cells=gdf_grid,\n",
    "    grid_cells_crs=5070,\n",
    "    # grid_cells_crs=4326,\n",
    "    filename=weightspath,\n",
    "    wght_gen_crs=5070,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weighted soil moisture for HU10 polygons\n",
    "if isinstance(wght_n, pd.DataFrame):\n",
    "    newgdf, vals = run_weights(\n",
    "        var=var,\n",
    "        time=timedimension,\n",
    "        ds=data,\n",
    "        wght_file=wght_n,\n",
    "        shp=gdf,\n",
    "        geom_id=polygon_index,\n",
    "    )\n",
    "\n",
    "    print(vals)\n",
    "\n",
    "newgdf[var] = vals[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify area of interest based on the extent of the Saint Croix watershed HU10 subset\n",
    "bounds = newgdf.total_bounds\n",
    "print(bounds)\n",
    "\n",
    "# extract linear unit y and x values\n",
    "x_min, y_min = bounds[1], bounds[0]\n",
    "x_max, y_max = bounds[3], bounds[2]\n",
    "\n",
    "# Convert linear x and y values to longitudes and latitudes\n",
    "lat_min, lon_min = pyproj.transform(pyproj.Proj('epsg:5070'), pyproj.Proj('epsg:4326'), y_min, x_min)\n",
    "lat_max, lon_max = pyproj.transform(pyproj.Proj('epsg:5070'), pyproj.Proj('epsg:4326'), y_max, x_max)\n",
    "print('lon_min', lon_min, 'lon_max', lon_max, 'lat_min', lat_min, 'lat_max', lat_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SOILM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'Saint Croix NLDAS Surface Soil Moisture kg/m^2 for'\n",
    "rawdata = data.SOILM[0,:,:].hvplot.quadmesh( # Input surface soil moisture grid\n",
    "    'lon', # x coordinates\n",
    "    'lat', # y coordinates\n",
    "    var, # data variable to be displayed, set in first cell\n",
    "    #crs = \n",
    "    projection=cartopy.crs.AlbersEqualArea(-91, 45), # Albers Equal Area centered on Saint Croix watershed\n",
    "    global_extent=False,  \n",
    "    ylim=(lat_min-1, lat_max+1), # use slightly larger bounding box than that retrieved from the gdf dataset\n",
    "    xlim=(lon_min-1, lon_max+1), \n",
    "    clim=(12,30), # dataset visualization graduation range for soil moisture\n",
    "    alpha=0.5)\n",
    "poly_weighted = newgdf.hvplot.polygons( # HU10 watershed catchment polygon-weighted surface soil moisture\n",
    "    c=var, # data variable to be displayed, set in first cell\n",
    "    crs=5070, # Albers Equal Area\n",
    "    line_width=0.5, \n",
    "    line_color='white', \n",
    "    clim=(12,30), # dataset visualization graduation range for soil moisture\n",
    "    alpha=1, \n",
    "    label = \"Saint Croix HU10\") # add toggleable legend element, adding the option to make the polygons mostly transparent in order to compare against the gridded data\n",
    "# stateshv = states.hvplot.polygons( # state outline dataset\n",
    "#     crs=5070, \n",
    "#     line_width=0.5, \n",
    "#     line_color='black', \n",
    "#     alpha=1, \n",
    "#     color=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine layers into a single map\n",
    "combinedmap = (poly_weighted * rawdata).relabel(title).opts(legend_position='bottom', width=500, height=500)\n",
    "combinedmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe0964851f04ea6586e377f078c404bbf53f5c0533ed43693e51c8780a3d4fa0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gdptools-ex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
